{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1wzYIpxbwo5_up9Z-_JoD6S8ZDVgJN2mJ","timestamp":1684580685246}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"iCFpOSQDCHKJ"},"cell_type":"markdown","source":["# GAN Implementation\n","Concepts:\n","Two networks, Generator (G) and Discriminator (D) play a game of fooling each other. G is trying to trick D by generating fake data and D is trying to get better at discriminating fake data from real. \n","\n","D is trained on real *and* fake data; G is trained on fake data labelled as true while using D's gradients to get better at generating fake data. As the game of fooling continues, G gets better as generating fake data and D gets better at discriminating fake data.\n","\n","Binary cross-entropy or Kullback-Liebler (KL) Divergence: the distance between two (probability for KD) distributions.\n","\n","DCGAD (Deep Convolution Generative Adversarial Networks) are more intended for images."]},{"metadata":{"id":"WvthZNkqFGie"},"cell_type":"markdown","source":["# Imports\n","\n","We start with imports and parameters "]},{"metadata":{"id":"GLDaD64ACDCJ","executionInfo":{"status":"ok","timestamp":1684580884563,"user_tz":-120,"elapsed":27534,"user":{"displayName":"Alessandro","userId":"01797529013394149771"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"a52886b0-20fe-4337-9fb9-5ab719a9b404"},"cell_type":"code","source":["import os\n","import numpy as np\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","import keras\n","from keras.models import Model, Sequential\n","from keras.layers import Dense, BatchNormalization, Reshape, Dropout, LeakyReLU, Input, Flatten\n","from keras.optimizers import Adam\n","from keras.datasets import mnist\n","from keras.utils import plot_model\n","\n","from google.colab import drive\n","drive.mount('/content/gdrive', force_remount=True)"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}]},{"cell_type":"code","source":["# CHANGE THIS PATH TO YOUR FOLDER'S PATH\n","path = \"/content/gdrive/MyDrive/corsoDL_UniVPM/GAN_Ese_Master\"\n","\n","if not os.path.exists(os.path.join(path, \"gen_images\")):\n","  os.mkdir(os.path.join(path, \"gen_images\"))"],"metadata":{"id":"ix0Ns-gl5Fr_","executionInfo":{"status":"ok","timestamp":1684585622133,"user_tz":-120,"elapsed":240,"user":{"displayName":"Alessandro","userId":"01797529013394149771"}}},"execution_count":13,"outputs":[]},{"metadata":{"id":"q04HJQajCMY1","executionInfo":{"status":"ok","timestamp":1684585909103,"user_tz":-120,"elapsed":660,"user":{"displayName":"Alessandro","userId":"01797529013394149771"}}},"cell_type":"code","source":["# Parameters\n","epochs = 20000\n","mnist_shape = (28,28,1)\n","batch_size = 128\n","noise_shape = (100,)    # the bigger the random input vector, the more \"random\" the generated images will be\n","save_every = 1000"],"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":["We will use the MNIST dataset:\n","\n","<img src='https://upload.wikimedia.org/wikipedia/commons/2/27/MnistExamples.png'> <br>\n","It displays hand-written digits from 0 to 9. We want G to be able to generate new (*fake*) images that could be extracted from this dataset."],"metadata":{"id":"Mrze4G9a2fin"}},{"cell_type":"markdown","source":["# GAN structure"],"metadata":{"id":"ZamB9LHm42ON"}},{"cell_type":"markdown","source":["<img src='https://developers.google.com/static/machine-learning/gan/images/gan_diagram.svg'>\n","\n","The Generator model receives random (white) noise as input and processes it in order to produce images that look like the real ones. <br> The backpropagation of the error cannot take place without the Discriminator, which is a classifier: \n","\n","\n","1.   G generates a new sample from random noise;\n","2.   D receives the generated samples and the real ones;\n","3.   D has to classify the images it receives as \"real\" or \"fake\".\n","\n","D is trained to recognize that an image is fake, and G is trained to generate images that D cannot recognize as fake. \n"],"metadata":{"id":"s5PNoGbZ430M"}},{"metadata":{"id":"2o13r8M_CQ1Q"},"cell_type":"markdown","source":["# Generator"]},{"metadata":{"id":"06O5G68aCObQ","executionInfo":{"status":"ok","timestamp":1684588924534,"user_tz":-120,"elapsed":637,"user":{"displayName":"Alessandro","userId":"01797529013394149771"}}},"cell_type":"code","source":["def build_generator(noise_shape, mnist_shape):\n","    # It's a Fully Connected Neueal Network\n","    noise = Input(shape=noise_shape)    \n","    \n","    # first fully connected + activation + normalization\n","    x = Dense(256, input_shape=(noise_shape))(noise)  # fully connected layer\n","    x = LeakyReLU(alpha=0.2)(x)\n","    x = BatchNormalization(momentum=0.8)(x)\n","    # second fully connected + activation + normalization\n","    x = Dense(512)(x)\n","    x = LeakyReLU(alpha=0.2)(x)\n","    x = BatchNormalization(momentum=0.8)(x)\n","    # third fully connected + activation + normalization\n","    x = Dense(1024)(x)\n","    x = LeakyReLU(alpha=0.2)(x)\n","    x = BatchNormalization(momentum=0.8)(x)\n","    # final fully connected\n","    # mnist_shape = (28x28x1) --> np.prod(mnist_shape) = 28*28 = 784\n","    # the final Dense has as many neurons as many pixels there are in the original images\n","    x = Dense(np.prod(mnist_shape), activation='tanh')(x) #hyperbolic tangent --X everything is [-1;1]\n","    x = Reshape(mnist_shape)(x) # (784,1) --> (28, 28, 1)\n","    \n","    model = Model(noise, x)\n","    \n","    # print model summary\n","    model.summary()\n","    \n","    img = model(noise)\n","    return Model(noise, img)"],"execution_count":21,"outputs":[]},{"metadata":{"id":"L8soSUTHCa6N","colab":{"base_uri":"https://localhost:8080/"},"outputId":"05dd4f53-e90e-4d7c-b8de-b5e7abfff039","executionInfo":{"status":"ok","timestamp":1684588925237,"user_tz":-120,"elapsed":10,"user":{"displayName":"Alessandro","userId":"01797529013394149771"}}},"cell_type":"code","source":["G = build_generator(noise_shape, mnist_shape)\n","# input*weight + bias --> weight and bias are the parameters to train\n","# the first layer has 25856 parameters = 256weights*100inputs + 256 biases"],"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model_8\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_6 (InputLayer)        [(None, 100)]             0         \n","                                                                 \n"," dense_10 (Dense)            (None, 256)               25856     \n","                                                                 \n"," leaky_re_lu_7 (LeakyReLU)   (None, 256)               0         \n","                                                                 \n"," batch_normalization_3 (Batc  (None, 256)              1024      \n"," hNormalization)                                                 \n","                                                                 \n"," dense_11 (Dense)            (None, 512)               131584    \n","                                                                 \n"," leaky_re_lu_8 (LeakyReLU)   (None, 512)               0         \n","                                                                 \n"," batch_normalization_4 (Batc  (None, 512)              2048      \n"," hNormalization)                                                 \n","                                                                 \n"," dense_12 (Dense)            (None, 1024)              525312    \n","                                                                 \n"," leaky_re_lu_9 (LeakyReLU)   (None, 1024)              0         \n","                                                                 \n"," batch_normalization_5 (Batc  (None, 1024)             4096      \n"," hNormalization)                                                 \n","                                                                 \n"," dense_13 (Dense)            (None, 784)               803600    \n","                                                                 \n"," reshape_1 (Reshape)         (None, 28, 28, 1)         0         \n","                                                                 \n","=================================================================\n","Total params: 1,493,520\n","Trainable params: 1,489,936\n","Non-trainable params: 3,584\n","_________________________________________________________________\n"]}]},{"metadata":{"id":"L6ru59JXCUmy"},"cell_type":"markdown","source":["# Discriminator"]},{"metadata":{"id":"4dDuQuHOCY_2","executionInfo":{"status":"ok","timestamp":1684588925673,"user_tz":-120,"elapsed":10,"user":{"displayName":"Alessandro","userId":"01797529013394149771"}}},"cell_type":"code","source":["def build_discriminator(mnist_shape):\n","    # a classifier\n","    input = Input(shape=mnist_shape)\n","    \n","    #2D images become 1D arrays: 28x28x1 --> 784,1\n","    x = Flatten()(input)  \n","    # first fully-connected + activation\n","    x = Dense(512)(x)\n","    x = LeakyReLU(alpha=0.2)(x)\n","    # x = BatchNormalization()(x)\n","    # second fully-connected + activation\n","    x = Dense(256)(x)\n","    x = LeakyReLU(alpha=0.2)(x)\n","    # output fully-connected: probability that the input image is real \n","    x = Dense(1, activation='sigmoid')(x)\n","    \n","    model = Model(input, x)\n","    model.summary()\n","    img = model(input)\n","    return Model(input, img)"],"execution_count":23,"outputs":[]},{"metadata":{"id":"KHmkZi_-DG-p","colab":{"base_uri":"https://localhost:8080/"},"outputId":"c6b4577b-4d1a-444d-961f-c1527fcaa178","executionInfo":{"status":"ok","timestamp":1684588925673,"user_tz":-120,"elapsed":9,"user":{"displayName":"Alessandro","userId":"01797529013394149771"}}},"cell_type":"code","source":["D = build_discriminator(mnist_shape)"],"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model_10\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_7 (InputLayer)        [(None, 28, 28, 1)]       0         \n","                                                                 \n"," flatten_2 (Flatten)         (None, 784)               0         \n","                                                                 \n"," dense_14 (Dense)            (None, 512)               401920    \n","                                                                 \n"," leaky_re_lu_10 (LeakyReLU)  (None, 512)               0         \n","                                                                 \n"," dense_15 (Dense)            (None, 256)               131328    \n","                                                                 \n"," leaky_re_lu_11 (LeakyReLU)  (None, 256)               0         \n","                                                                 \n"," dense_16 (Dense)            (None, 1)                 257       \n","                                                                 \n","=================================================================\n","Total params: 533,505\n","Trainable params: 533,505\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"metadata":{"id":"FUDTyR30DLlw"},"cell_type":"markdown","source":["# Compile"]},{"metadata":{"id":"ZzmpdJkIDI0N","executionInfo":{"status":"ok","timestamp":1684588925674,"user_tz":-120,"elapsed":5,"user":{"displayName":"Alessandro","userId":"01797529013394149771"}}},"cell_type":"code","source":["G.compile(optimizer=Adam(0.0002, 0.5), loss='binary_crossentropy')\n","D.compile(optimizer=Adam(0.0002, 0.5), loss='binary_crossentropy', metrics=['accuracy'])"],"execution_count":25,"outputs":[]},{"metadata":{"id":"nf8aHC-hDSGO"},"cell_type":"markdown","source":["# Build GAN"]},{"cell_type":"markdown","source":["G is never trained alone: we train D to correctly label real and fake images, then we train the whole GAN (D+G) so that G generates images that are closer to what D would label as \"real\"."],"metadata":{"id":"aNuGbktBBJuc"}},{"metadata":{"id":"3-Sv0FndDUJ1","colab":{"base_uri":"https://localhost:8080/"},"outputId":"066047a3-b160-45f6-93e5-fa1b93860a62","executionInfo":{"status":"ok","timestamp":1684588926629,"user_tz":-120,"elapsed":4,"user":{"displayName":"Alessandro","userId":"01797529013394149771"}}},"cell_type":"code","source":["input = Input(shape=noise_shape)\n","fake_image = G(input)\n","D.trainable = False # we are \"freezing\" D's parameters: D won't be trained at first\n","real_or_fake_prob = D(fake_image)\n","# noise -> G -> D\n","D_G_model = Model(input, real_or_fake_prob)\n","D_G_model.compile(optimizer=Adam(0.0002, 0.5), loss='binary_crossentropy')\n","\n","D_G_model.summary()"],"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model_12\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_8 (InputLayer)        [(None, 100)]             0         \n","                                                                 \n"," model_9 (Functional)        (None, 28, 28, 1)         1493520   \n","                                                                 \n"," model_11 (Functional)       (None, 1)                 533505    \n","                                                                 \n","=================================================================\n","Total params: 2,027,025\n","Trainable params: 1,489,936\n","Non-trainable params: 537,089\n","_________________________________________________________________\n"]}]},{"metadata":{"id":"0mdE1agsDYvP","executionInfo":{"status":"ok","timestamp":1684588927135,"user_tz":-120,"elapsed":3,"user":{"displayName":"Alessandro","userId":"01797529013394149771"}}},"cell_type":"code","source":["def save_image(epoch):\n","    # we plot 5 x 5 grid of images and save it to disk along with epoch number\n","    rows = 10\n","    cols = 10\n","    \n","    noise = np.random.uniform(0, 1, (rows*cols, noise_shape[0]))\n","    images = G.predict(noise)\n","    \n","    # rescale\n","    images = 0.5 * images + 0.5\n","    \n","    # stuff to have 100 generated images all together in one 10x10 matrix\n","    fig, ax = plt.subplots(rows, cols)\n","    ctr = 0\n","    for i in range(rows):\n","        for j in range(cols):\n","            ax[i,j].imshow(images[ctr, :,:, 0], cmap='gray')\n","            ax[i,j].axis('off')\n","            ctr += 1\n","    if not os.path.exists('images'):\n","      os.makedirs('images')\n","\n","    fname = os.path.join(path,'gen_images', 'mnist_{}.png'.format(int(epoch/save_every)))\n","    fig.savefig(fname)\n","    print('saved: {}'.format(fname))\n","    plt.close()"],"execution_count":27,"outputs":[]},{"metadata":{"id":"yG9XK1ErDiqL"},"cell_type":"markdown","source":["# Train\n","\n","We will load the dataset, preprocess it and train the network"]},{"metadata":{"id":"32G80u6DDiCy","colab":{"base_uri":"https://localhost:8080/"},"outputId":"70b98cac-202a-4a08-8605-ae8eaf4d9c6b","executionInfo":{"status":"ok","timestamp":1684590843572,"user_tz":-120,"elapsed":1915109,"user":{"displayName":"Alessandro","userId":"01797529013394149771"}}},"cell_type":"code","source":["# Load dataset\n","(X_train, _), (_,_) = mnist.load_data()\n","X_train.shape\n","\n","# center data\n","# standardization: img - img.mean / img.std\n","# centering: img - 255/2 / (255/2)\n","X_train = (X_train.astype('float32') - 127.5)/127.5\n","\n","X_train = np.expand_dims(X_train, axis=3) # (28x28) --> (28x28x1)\n","print(\"X_train.shape =\", X_train.shape)\n","print(\"mean = \", np.mean(X_train), \"std = \", np.std(X_train))\n","\n","###########\n","# Train\n","# we want to train discriminator by passing half batch of real and half batch of fake images\n","# class balance: if I have 10 classes I want the net to see the same amount of imgs for each class\n","half_batch = int(batch_size/2)\n","print('half batch size : {}'.format(half_batch))\n","for epoch in range(epochs):\n","    #### train discriminator\n","    # 1) real: get a batch of real images and train D to label tham as \"real\" (1)\n","    indices = np.random.randint(0, X_train.shape[0], half_batch)\n","    real_images = X_train[indices]    \n","    d_real_loss = D.train_on_batch(real_images, np.ones((half_batch, 1))) #np.ones = output 1 for each image\n","    \n","    # 2) fake: get a batch of fake images and train D to label tham as \"fake\" (0)\n","    noise = np.random.uniform(0, 1, (half_batch, noise_shape[0]))\n","    fake_images = G.predict(noise, verbose=0)\n","    d_fake_loss = D.train_on_batch(fake_images, np.zeros((half_batch, 1)))\n","    \n","    # Total D loss = loss on real data + loss on fake data\n","    d_loss = np.add(d_real_loss, d_fake_loss) / 2\n","    \n","    #### 3) train generator: we give the random input to the GAN (D+G)\n","    noise = np.random.uniform(0, 1, (batch_size, noise_shape[0]))\n","    g_loss = D_G_model.train_on_batch(noise, np.ones((batch_size, 1)))\n","    # in D_G_model, the Discriminator is NEVER trained, so it's only the Generator that \n","    # improves its generative ability according to what the Discriminator has learnt in 1) and 2)\n","        \n","    if epoch % 500 == 0:\n","      print(f'Epoch: {epoch}, D_Loss:{d_loss[0]}, D_Acc:{d_loss[1],}, G_Loss:{g_loss}')\n","\n","    if epoch % save_every == 0:        \n","        save_image(epoch)      "],"execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["X_train.shape = (60000, 28, 28, 1)\n","mean =  -0.7386798 std =  0.6162155\n","half batch size : 64\n","Epoch: 0, D_Loss:0.8698620498180389, D_Acc:(0.5,), G_Loss:0.9543672800064087\n","4/4 [==============================] - 0s 3ms/step\n","saved: /content/gdrive/MyDrive/corsoDL_UniVPM/GAN_Ese_Master/gen_images/mnist_0.png\n","Epoch: 500, D_Loss:0.6175688803195953, D_Acc:(0.5390625,), G_Loss:0.7963272929191589\n","Epoch: 1000, D_Loss:0.5783383250236511, D_Acc:(0.8359375,), G_Loss:0.9672702550888062\n","4/4 [==============================] - 0s 3ms/step\n","saved: /content/gdrive/MyDrive/corsoDL_UniVPM/GAN_Ese_Master/gen_images/mnist_1.png\n","Epoch: 1500, D_Loss:0.5786908268928528, D_Acc:(0.6953125,), G_Loss:1.1366784572601318\n","Epoch: 2000, D_Loss:0.5897597372531891, D_Acc:(0.6484375,), G_Loss:1.1305128335952759\n","4/4 [==============================] - 0s 3ms/step\n","saved: /content/gdrive/MyDrive/corsoDL_UniVPM/GAN_Ese_Master/gen_images/mnist_2.png\n","Epoch: 2500, D_Loss:0.5778942108154297, D_Acc:(0.7109375,), G_Loss:1.0227787494659424\n","Epoch: 3000, D_Loss:0.6303078830242157, D_Acc:(0.6484375,), G_Loss:0.9764641523361206\n","4/4 [==============================] - 0s 3ms/step\n","saved: /content/gdrive/MyDrive/corsoDL_UniVPM/GAN_Ese_Master/gen_images/mnist_3.png\n","Epoch: 3500, D_Loss:0.6570484340190887, D_Acc:(0.6171875,), G_Loss:0.9255639910697937\n","Epoch: 4000, D_Loss:0.6691461503505707, D_Acc:(0.6015625,), G_Loss:0.8376551270484924\n","4/4 [==============================] - 0s 4ms/step\n","saved: /content/gdrive/MyDrive/corsoDL_UniVPM/GAN_Ese_Master/gen_images/mnist_4.png\n","Epoch: 4500, D_Loss:0.6675059795379639, D_Acc:(0.6015625,), G_Loss:0.8623536229133606\n","Epoch: 5000, D_Loss:0.6820383071899414, D_Acc:(0.625,), G_Loss:0.8631942272186279\n","4/4 [==============================] - 0s 3ms/step\n","saved: /content/gdrive/MyDrive/corsoDL_UniVPM/GAN_Ese_Master/gen_images/mnist_5.png\n","Epoch: 5500, D_Loss:0.6528906226158142, D_Acc:(0.671875,), G_Loss:0.8441314101219177\n","Epoch: 6000, D_Loss:0.6578152775764465, D_Acc:(0.6484375,), G_Loss:0.8475282192230225\n","4/4 [==============================] - 0s 3ms/step\n","saved: /content/gdrive/MyDrive/corsoDL_UniVPM/GAN_Ese_Master/gen_images/mnist_6.png\n","Epoch: 6500, D_Loss:0.6742185354232788, D_Acc:(0.6328125,), G_Loss:0.846537709236145\n","Epoch: 7000, D_Loss:0.6839135587215424, D_Acc:(0.578125,), G_Loss:0.8125776052474976\n","4/4 [==============================] - 0s 3ms/step\n","saved: /content/gdrive/MyDrive/corsoDL_UniVPM/GAN_Ese_Master/gen_images/mnist_7.png\n","Epoch: 7500, D_Loss:0.6932806074619293, D_Acc:(0.5078125,), G_Loss:0.7819518446922302\n","Epoch: 8000, D_Loss:0.695989191532135, D_Acc:(0.5703125,), G_Loss:0.8482136130332947\n","4/4 [==============================] - 0s 4ms/step\n","saved: /content/gdrive/MyDrive/corsoDL_UniVPM/GAN_Ese_Master/gen_images/mnist_8.png\n","Epoch: 8500, D_Loss:0.692520022392273, D_Acc:(0.5546875,), G_Loss:0.7749425768852234\n","Epoch: 9000, D_Loss:0.683783769607544, D_Acc:(0.546875,), G_Loss:0.8086715936660767\n","4/4 [==============================] - 0s 3ms/step\n","saved: /content/gdrive/MyDrive/corsoDL_UniVPM/GAN_Ese_Master/gen_images/mnist_9.png\n","Epoch: 9500, D_Loss:0.6939310729503632, D_Acc:(0.5546875,), G_Loss:0.8261259198188782\n","Epoch: 10000, D_Loss:0.6715424656867981, D_Acc:(0.578125,), G_Loss:0.8276529312133789\n","4/4 [==============================] - 0s 3ms/step\n","saved: /content/gdrive/MyDrive/corsoDL_UniVPM/GAN_Ese_Master/gen_images/mnist_10.png\n","Epoch: 10500, D_Loss:0.7235975861549377, D_Acc:(0.46875,), G_Loss:0.8063843250274658\n","Epoch: 11000, D_Loss:0.7014467716217041, D_Acc:(0.5625,), G_Loss:0.8141627311706543\n","4/4 [==============================] - 0s 4ms/step\n","saved: /content/gdrive/MyDrive/corsoDL_UniVPM/GAN_Ese_Master/gen_images/mnist_11.png\n","Epoch: 11500, D_Loss:0.6767323315143585, D_Acc:(0.6171875,), G_Loss:0.7893041372299194\n","Epoch: 12000, D_Loss:0.7010109126567841, D_Acc:(0.53125,), G_Loss:0.8046889305114746\n","4/4 [==============================] - 0s 3ms/step\n","saved: /content/gdrive/MyDrive/corsoDL_UniVPM/GAN_Ese_Master/gen_images/mnist_12.png\n","Epoch: 12500, D_Loss:0.6686892509460449, D_Acc:(0.609375,), G_Loss:0.8113586902618408\n","Epoch: 13000, D_Loss:0.6892156600952148, D_Acc:(0.5390625,), G_Loss:0.8169854879379272\n","4/4 [==============================] - 0s 3ms/step\n","saved: /content/gdrive/MyDrive/corsoDL_UniVPM/GAN_Ese_Master/gen_images/mnist_13.png\n","Epoch: 13500, D_Loss:0.673942893743515, D_Acc:(0.5625,), G_Loss:0.8369058966636658\n","Epoch: 14000, D_Loss:0.6784877479076385, D_Acc:(0.5859375,), G_Loss:0.8565747737884521\n","4/4 [==============================] - 0s 3ms/step\n","saved: /content/gdrive/MyDrive/corsoDL_UniVPM/GAN_Ese_Master/gen_images/mnist_14.png\n","Epoch: 14500, D_Loss:0.6892380118370056, D_Acc:(0.5625,), G_Loss:0.8182454705238342\n","Epoch: 15000, D_Loss:0.6989395320415497, D_Acc:(0.5546875,), G_Loss:0.8354496955871582\n","4/4 [==============================] - 0s 3ms/step\n","saved: /content/gdrive/MyDrive/corsoDL_UniVPM/GAN_Ese_Master/gen_images/mnist_15.png\n","Epoch: 15500, D_Loss:0.6627547442913055, D_Acc:(0.5703125,), G_Loss:0.8462801575660706\n","Epoch: 16000, D_Loss:0.6856848001480103, D_Acc:(0.5625,), G_Loss:0.8233557343482971\n","4/4 [==============================] - 0s 3ms/step\n","saved: /content/gdrive/MyDrive/corsoDL_UniVPM/GAN_Ese_Master/gen_images/mnist_16.png\n","Epoch: 16500, D_Loss:0.7268814742565155, D_Acc:(0.46875,), G_Loss:0.8137202858924866\n","Epoch: 17000, D_Loss:0.6692013740539551, D_Acc:(0.546875,), G_Loss:0.8420894145965576\n","4/4 [==============================] - 0s 4ms/step\n","saved: /content/gdrive/MyDrive/corsoDL_UniVPM/GAN_Ese_Master/gen_images/mnist_17.png\n","Epoch: 17500, D_Loss:0.7098447680473328, D_Acc:(0.5546875,), G_Loss:0.8143603205680847\n","Epoch: 18000, D_Loss:0.7191537320613861, D_Acc:(0.4765625,), G_Loss:0.8303905725479126\n","4/4 [==============================] - 0s 4ms/step\n","saved: /content/gdrive/MyDrive/corsoDL_UniVPM/GAN_Ese_Master/gen_images/mnist_18.png\n","Epoch: 18500, D_Loss:0.6583298742771149, D_Acc:(0.640625,), G_Loss:0.8012856245040894\n","Epoch: 19000, D_Loss:0.6775860786437988, D_Acc:(0.546875,), G_Loss:0.8287510871887207\n","4/4 [==============================] - 0s 2ms/step\n","saved: /content/gdrive/MyDrive/corsoDL_UniVPM/GAN_Ese_Master/gen_images/mnist_19.png\n","Epoch: 19500, D_Loss:0.6824371516704559, D_Acc:(0.6015625,), G_Loss:0.8437705039978027\n"]}]},{"metadata":{"id":"pJiinY4jEJqc"},"cell_type":"markdown","source":["# Test \n","\n","We are now ready to test the generator by passing random noise and checking what it generates"]},{"metadata":{"id":"yQBDjmNKEJGa","colab":{"base_uri":"https://localhost:8080/","height":465},"outputId":"a4c5d305-4d86-4f2c-b1e8-4864bfe5271b","executionInfo":{"status":"ok","timestamp":1684592229347,"user_tz":-120,"elapsed":643,"user":{"displayName":"Alessandro","userId":"01797529013394149771"}}},"cell_type":"code","source":["noise = np.random.uniform(0, 1, (1, noise_shape[0]))\n","image = G.predict(noise)\n","\n","# Visualise\n","plt.imshow(image[0,:,:, 0], cmap='gray')"],"execution_count":47,"outputs":[{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 20ms/step\n"]},{"output_type":"execute_result","data":{"text/plain":["<matplotlib.image.AxesImage at 0x7fa1ec402a40>"]},"metadata":{},"execution_count":47},{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"markdown","source":["## controllo aggiornamento colab"],"metadata":{"id":"MuxrlMTpiNrG"}}]}